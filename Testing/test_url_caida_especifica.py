#!/usr/bin/env python3
"""
Script especÃ­fico para analizar una URL 'caÃ­da' que tÃ©cnicamente responde con HTML
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import Z_Utils as Z
import logging
from bs4 import BeautifulSoup

# Configurar logging para ver los mensajes
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

def analizar_url_caida():
    """Analiza especÃ­ficamente la URL caÃ­da para entender cÃ³mo la interpreta el sistema"""
    
    print("ğŸ§ª Analizando URL 'caÃ­da' especÃ­fica...")
    print("=" * 70)
    
    # La URL especÃ­fica que quieres analizar
    url_caida = "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=14632596"
    
    print(f"ğŸ”— URL a analizar: {url_caida}")
    print("-" * 50)
    
    # PASO 1: Probar con procesar_link_robusto (tipo='texto')
    print("ğŸ“ PASO 1: Probando extracciÃ³n de TEXTO PLANO...")
    print("-" * 30)
    
    texto_plano = Z.procesar_link_robusto(url_caida, 'texto', 3)
    
    if texto_plano:
        print(f"âœ… TEXTO extraÃ­do exitosamente:")
        print(f"ğŸ“ Longitud: {len(texto_plano)} caracteres")
        print(f"ğŸ“„ Contenido: {texto_plano}")
        print()
    else:
        print("âŒ TEXTO fallÃ³: None")
        print()
    
    # PASO 2: Probar con procesar_link_robusto (tipo='html')
    print("ğŸŒ PASO 2: Probando extracciÃ³n de HTML...")
    print("-" * 30)
    
    html_obj = Z.procesar_link_robusto(url_caida, 'html', 3)
    
    if html_obj:
        print(f"âœ… HTML extraÃ­do exitosamente:")
        print(f"ğŸ“ Longitud del HTML: {len(str(html_obj))} caracteres")
        
        # Analizar el contenido del HTML
        print(f"ğŸ·ï¸ TÃ­tulo de la pÃ¡gina: {html_obj.title.string if html_obj.title else 'No encontrado'}")
        
        # Buscar el mensaje de error especÃ­fico
        error_msg = html_obj.find(text=lambda text: text and "no se encuentra" in text.lower())
        if error_msg:
            print(f"âš ï¸ Mensaje de error detectado: {error_msg.strip()}")
        
        # Mostrar las primeras lÃ­neas del HTML
        html_text = html_obj.get_text(separator=' ', strip=True)
        print(f"ğŸ“„ Texto extraÃ­do del HTML: {html_text[:200]}...")
        print()
        
    else:
        print("âŒ HTML fallÃ³: None")
        print()
    
    # PASO 3: AnÃ¡lisis manual directo con requests
    print("ğŸ” PASO 3: AnÃ¡lisis manual directo...")
    print("-" * 30)
    
    try:
        import requests
        response = requests.get(url_caida, timeout=10)
        
        print(f"ğŸ“¡ Status Code: {response.status_code}")
        print(f"ğŸ“ TamaÃ±o de respuesta: {len(response.content)} bytes")
        print(f"ğŸ”¤ Encoding: {response.encoding}")
        
        if response.status_code == 200:
            print("âœ… Servidor respondiÃ³ exitosamente")
            
            # Parsear manualmente
            soup_manual = BeautifulSoup(response.text, 'html.parser')
            
            # Buscar elementos especÃ­ficos
            titulo_manual = soup_manual.find('title')
            if titulo_manual:
                print(f"ğŸ·ï¸ TÃ­tulo manual: {titulo_manual.string}")
            
            # Buscar el mensaje de error
            error_manual = soup_manual.find(text=lambda text: text and "no se encuentra" in text.lower())
            if error_manual:
                print(f"âš ï¸ Error manual: {error_manual.strip()}")
            
            # Mostrar estructura del HTML
            print(f"ğŸ—ï¸ Estructura HTML: {len(soup_manual.find_all())} elementos encontrados")
            
        else:
            print(f"âŒ Servidor respondiÃ³ con error: {response.status_code}")
            
    except Exception as e:
        print(f"âŒ Error en anÃ¡lisis manual: {e}")
    
    print("\n" + "=" * 70)
    print("ğŸ¯ ANÃLISIS COMPLETADO")
    print("=" * 70)

if __name__ == "__main__":
    analizar_url_caida()
