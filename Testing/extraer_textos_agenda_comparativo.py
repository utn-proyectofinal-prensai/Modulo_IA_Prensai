#!/usr/bin/env python3
"""
Script para extraer texto plano de URLs de agenda (S√ç y NO) para an√°lisis comparativo
"""

import sys
import os

# Agregar el directorio ra√≠z al path para importar m√≥dulos
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from Z_Utils import get_texto_plano_from_link

def extraer_textos_agenda():
    """Extrae texto plano de todas las URLs de agenda para an√°lisis comparativo"""
    
    # URLs que S√ç son agenda
    urls_si_agenda = [
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24294600",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24302208",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24347481",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24196084",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24185308",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24257893",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=23662034",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=23595633",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=23595797"
    ]
    
    # URLs que NO son agenda
    urls_no_agenda = [
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24069245",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24136111",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24049682",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=23932884",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=23370658",
        "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=23432671"
    ]
    
    # Archivo de salida
    output_file = "textos_agenda_comparativo.txt"
    
    print("üöÄ Iniciando extracci√≥n de textos para an√°lisis comparativo de agenda...")
    print(f"üìä URLs que S√ç son agenda: {len(urls_si_agenda)}")
    print(f"üìä URLs que NO son agenda: {len(urls_no_agenda)}")
    print("=" * 80)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        # Escribir encabezado
        f.write("TEXTOS COMPARATIVOS PARA AN√ÅLISIS DE AGENDA\n")
        f.write("=" * 80 + "\n\n")
        
        # Procesar URLs que S√ç son agenda
        f.write("üîµ SECCI√ìN 1: URLs que S√ç son agenda\n")
        f.write("=" * 50 + "\n\n")
        
        for i, url in enumerate(urls_si_agenda, 1):
            print(f"üì∞ Procesando agenda S√ç #{i}: {url}")
            
            try:
                texto = get_texto_plano_from_link(url)
                if texto:
                    f.write(f"--- AGENDA S√ç #{i} ---\n")
                    f.write(f"URL: {url}\n")
                    f.write(f"TEXTO:\n{texto}\n")
                    f.write("-" * 80 + "\n\n")
                    print(f"‚úÖ Texto extra√≠do: {len(texto)} caracteres")
                else:
                    print(f"‚ùå No se pudo extraer texto de: {url}")
                    f.write(f"--- AGENDA S√ç #{i} ---\n")
                    f.write(f"URL: {url}\n")
                    f.write("ERROR: No se pudo extraer texto\n")
                    f.write("-" * 80 + "\n\n")
            except Exception as e:
                print(f"‚ùå Error procesando {url}: {e}")
                f.write(f"--- AGENDA S√ç #{i} ---\n")
                f.write(f"URL: {url}\n")
                f.write(f"ERROR: {e}\n")
                f.write("-" * 80 + "\n\n")
        
        # Separador entre secciones
        f.write("\n" + "=" * 80 + "\n\n")
        
        # Procesar URLs que NO son agenda
        f.write("üî¥ SECCI√ìN 2: URLs que NO son agenda\n")
        f.write("=" * 50 + "\n\n")
        
        for i, url in enumerate(urls_no_agenda, 1):
            print(f"üì∞ Procesando agenda NO #{i}: {url}")
            
            try:
                texto = get_texto_plano_from_link(url)
                if texto:
                    f.write(f"--- AGENDA NO #{i} ---\n")
                    f.write(f"URL: {url}\n")
                    f.write(f"TEXTO:\n{texto}\n")
                    f.write("-" * 80 + "\n\n")
                    print(f"‚úÖ Texto extra√≠do: {len(texto)} caracteres")
                else:
                    print(f"‚ùå No se pudo extraer texto de: {url}")
                    f.write(f"--- AGENDA NO #{i} ---\n")
                    f.write(f"URL: {url}\n")
                    f.write("ERROR: No se pudo extraer texto\n")
                    f.write("-" * 80 + "\n\n")
            except Exception as e:
                print(f"‚ùå Error procesando {url}: {e}")
                f.write(f"--- AGENDA NO #{i} ---\n")
                f.write(f"URL: {url}\n")
                f.write(f"ERROR: {e}\n")
                f.write("-" * 80 + "\n\n")
        
        # Escribir resumen
        f.write("\n" + "=" * 80 + "\n")
        f.write("RESUMEN DEL AN√ÅLISIS\n")
        f.write("=" * 80 + "\n")
        f.write(f"Total URLs que S√ç son agenda: {len(urls_si_agenda)}\n")
        f.write(f"Total URLs que NO son agenda: {len(urls_no_agenda)}\n")
        f.write(f"Total URLs procesadas: {len(urls_si_agenda) + len(urls_no_agenda)}\n")
        f.write("Archivo generado para an√°lisis comparativo del prompt de es_agenda_gpt\n")
    
    print(f"\n‚úÖ An√°lisis completado!")
    print(f"üìÅ Archivo generado: {output_file}")
    print(f"üìä Total de URLs procesadas: {len(urls_si_agenda) + len(urls_no_agenda)}")
    print("\nüéØ Ahora puedes revisar el archivo para analizar las diferencias")
    print("   y ajustar el prompt de es_agenda_gpt seg√∫n sea necesario")

if __name__ == "__main__":
    extraer_textos_agenda()
