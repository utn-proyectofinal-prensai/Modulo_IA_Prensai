#!/usr/bin/env python3
"""
TEST VALORACI√ìN CON GPT - COMPARATIVA COMPLETA
==============================================

Este script testea la funci√≥n de valoraci√≥n de noticias con diferentes modelos:
- GPT-4o (cuando gpt_active=True)
- GPT-3.5-turbo (cuando gpt_active=True) 
- Ollama (cuando gpt_active=False)

Compara los resultados con valoraciones humanas pre-asignadas.
"""

import sys
import os
import logging
import pandas as pd
from datetime import datetime

# Agregar el directorio padre al path para importar m√≥dulos
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from O_Utils_GPT import valorar_con_ia
from Z_Utils import procesar_link_robusto, marcar_o_valorar_con_ia

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('test_valoracion_gpt.log'),
        logging.StreamHandler()
    ]
)

# L√≠mite de texto para valoraci√≥n (igual que en la API)
LIMITE_TEXTO = 14900

# CASOS DE TEST - 32 URLs con valoraciones humanas
casos_test = [
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24313595",
        "valoracion_humana": "NEUTRA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24423099",
        "valoracion_humana": "POSITIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24423181",
        "valoracion_humana": "NEUTRA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24301580",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24301733",
        "valoracion_humana": "NEUTRA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24301275",
        "valoracion_humana": "NEUTRA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24361465",
        "valoracion_humana": "POSITIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24340866",
        "valoracion_humana": "POSITIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24326655",
        "valoracion_humana": "NEUTRA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24192610",
        "valoracion_humana": "POSITIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24172624",
        "valoracion_humana": "POSITIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24187599",
        "valoracion_humana": "NEUTRA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24189134",
        "valoracion_humana": "NEUTRA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24196084",
        "valoracion_humana": "NEUTRA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24196152",
        "valoracion_humana": "NEUTRA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=22838274",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=20420667",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=20402381",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=20271878",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=19799678",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=19674630",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=18961573",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=17867914",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=17918357",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=17815252",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=89819217",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=89161318",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=89163058",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=89129117",
        "valoracion_humana": "NEGATIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24291597",
        "valoracion_humana": "POSITIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=24070877",
        "valoracion_humana": "POSITIVA"
    },
    {
        "url": "https://culturagcba.clientes.ejes.com/noticia_completa.cfm?id=23561903",
        "valoracion_humana": "POSITIVA"
    }
]

def test_valoracion_gpt_35():
    """Test con GPT-3.5-turbo (gpt_active=True)"""
    print("\n" + "="*80)
    print("üß† TEST VALORACI√ìN CON GPT-3.5-TURBO")
    print("="*80)
    
    resultados = []
    exitosos = 0
    fallidos = 0
    
    for i, caso in enumerate(casos_test, 1):
        url = caso["url"]
        valoracion_humana = caso["valoracion_humana"]
        
        print(f"\nüì∞ [{i:2d}/32] Procesando: {url}")
        print(f"   üè∑Ô∏è  Valoraci√≥n humana: {valoracion_humana}")
        
        try:
            # Extraer texto de la URL usando procesar_link_robusto
            texto = procesar_link_robusto(url, tipo='texto', max_reintentos=3)
            
            if not texto:
                print("   ‚ùå No se pudo extraer texto despu√©s de reintentos")
                fallidos += 1
                resultados.append({
                    "url": url,
                    "valoracion_humana": valoracion_humana,
                    "valoracion_ia": "ERROR_EXTRACCION",
                    "acierto": False,
                    "error": "No se pudo extraer texto despu√©s de reintentos"
                })
                continue
            
            # Valorar con GPT-3.5 usando marcar_o_valorar_con_ia (como en la API)
            valoracion_ia = marcar_o_valorar_con_ia(
                texto,
                lambda t: valorar_con_ia(
                    t, 
                    gpt_active=True,
                    ministro_key_words=["Gabriela Ricardes", "Ministra de Cultura", "Victoria Noorthoorn", "Gerardo Grieco", "Jorge Macri"],
                    ministerios_key_words=["Ministerio de Cultura", "Ministerio de Cultura de Buenos Aires"]
                ),
                LIMITE_TEXTO
            )
            
            # Verificar acierto
            acierto = valoracion_ia.upper() == valoracion_humana.upper()
            if acierto:
                exitosos += 1
                print(f"   ‚úÖ GPT-3.5: {valoracion_ia} | ACIERTO")
            else:
                fallidos += 1
                print(f"   ‚ùå GPT-3.5: {valoracion_ia} | FALLO (esperado: {valoracion_humana})")
            
            resultados.append({
                "url": url,
                "valoracion_humana": valoracion_humana,
                "valoracion_ia": valoracion_ia,
                "acierto": acierto,
                "error": None
            })
            
        except Exception as e:
            print(f"   üí• Error: {str(e)}")
            fallidos += 1
            resultados.append({
                "url": url,
                "valoracion_humana": valoracion_humana,
                "valoracion_ia": "ERROR",
                "acierto": False,
                "error": str(e)
            })
    
    # Calcular m√©tricas
    precision = (exitosos / len(casos_test)) * 100 if casos_test else 0
    
    print(f"\nüìä RESULTADOS GPT-3.5:")
    print(f"   ‚úÖ Exitosos: {exitosos}/{len(casos_test)}")
    print(f"   ‚ùå Fallidos: {fallidos}/{len(casos_test)}")
    print(f"   üéØ Precisi√≥n: {precision:.1f}%")
    
    return resultados, precision

def test_valoracion_ollama():
    """Test con Ollama (gpt_active=False)"""
    print("\n" + "="*80)
    print("ü§ñ TEST VALORACI√ìN CON OLLAMA")
    print("="*80)
    
    resultados = []
    exitosos = 0
    fallidos = 0
    
    for i, caso in enumerate(casos_test, 1):
        url = caso["url"]
        valoracion_humana = caso["valoracion_humana"]
        
        print(f"\nüì∞ [{i:2d}/32] Procesando: {url}")
        print(f"   üè∑Ô∏è  Valoraci√≥n humana: {valoracion_humana}")
        
        try:
            # Extraer texto de la URL usando procesar_link_robusto
            texto = procesar_link_robusto(url, tipo='texto', max_reintentos=3)
            
            if not texto:
                print("   ‚ùå No se pudo extraer texto despu√©s de reintentos")
                fallidos += 1
                resultados.append({
                    "url": url,
                    "valoracion_humana": valoracion_humana,
                    "valoracion_ia": "ERROR_EXTRACCION",
                    "acierto": False,
                    "error": "No se pudo extraer texto despu√©s de reintentos"
                })
                continue
            
            # Valorar con Ollama usando marcar_o_valorar_con_ia (como en la API)
            valoracion_ia = marcar_o_valorar_con_ia(
                texto,
                lambda t: valorar_con_ia(
                    t, 
                    gpt_active=False,
                    ministro_key_words=["Gabriela Ricardes", "Ministra de Cultura", "Victoria Noorthoorn", "Gerardo Grieco", "Jorge Macri"],
                    ministerios_key_words=["Ministerio de Cultura", "Ministerio de Cultura de Buenos Aires"]
                ),
                LIMITE_TEXTO
            )
            
            # Verificar acierto
            acierto = valoracion_ia.upper() == valoracion_humana.upper()
            if acierto:
                exitosos += 1
                print(f"   ‚úÖ Ollama: {valoracion_ia} | ACIERTO")
            else:
                fallidos += 1
                print(f"   ‚ùå Ollama: {valoracion_ia} | FALLO (esperado: {valoracion_humana})")
            
            resultados.append({
                "url": url,
                "valoracion_humana": valoracion_humana,
                "valoracion_ia": valoracion_ia,
                "acierto": acierto,
                "error": None
            })
            
        except Exception as e:
            print(f"   üí• Error: {str(e)}")
            fallidos += 1
            resultados.append({
                "url": url,
                "valoracion_humana": valoracion_humana,
                "valoracion_ia": "ERROR",
                "acierto": False,
                "error": str(e)
            })
    
    # Calcular m√©tricas
    precision = (exitosos / len(casos_test)) * 100 if casos_test else 0
    
    print(f"\nüìä RESULTADOS OLLAMA:")
    print(f"   ‚úÖ Exitosos: {exitosos}/{len(casos_test)}")
    print(f"   ‚ùå Fallidos: {fallidos}/{len(casos_test)}")
    print(f"   üéØ Precisi√≥n: {precision:.1f}%")
    
    return resultados, precision

def generar_comparativa(resultados_gpt4o, precision_gpt4o, resultados_gpt35, precision_gpt35, resultados_ollama, precision_ollama):
    """Genera comparativa final de todos los modelos"""
    print("\n" + "="*80)
    print("üèÜ COMPARATIVA FINAL - VALORACI√ìN CON IA")
    print("="*80)
    
    print(f"\nüìä RESULTADOS COMPARATIVA - {len(casos_test)} CASOS REALES:")
    print()
    print("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
    print("‚îÇ   MODELO    ‚îÇ EXITOSOS ‚îÇ FALLIDOS ‚îÇ PRECISI√ìN‚îÇ RENDIMIENTO ‚îÇ")
    print("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
    
    # GPT-3.5
    fallidos_gpt35 = len(casos_test) - int((precision_gpt35 / 100) * len(casos_test))
    rendimiento_gpt35 = "üèÜ EXCELENTE" if precision_gpt35 >= 90 else "ü•à BUENO" if precision_gpt35 >= 80 else "ü•â REGULAR"
    print(f"‚îÇ  GPT-3.5    ‚îÇ   {int((precision_gpt35/100)*len(casos_test)):2d}/{len(casos_test):2d}   ‚îÇ   {fallidos_gpt35:2d}/{len(casos_test):2d}   ‚îÇ   {precision_gpt35:5.1f}%  ‚îÇ   {rendimiento_gpt35}       ‚îÇ")
    
    # Ollama
    fallidos_ollama = len(casos_test) - int((precision_ollama / 100) * len(casos_test))
    rendimiento_ollama = "üèÜ EXCELENTE" if precision_ollama >= 90 else "ü•à BUENO" if precision_ollama >= 80 else "ü•â REGULAR"
    print(f"‚îÇ  Ollama     ‚îÇ   {int((precision_ollama/100)*len(casos_test)):2d}/{len(casos_test):2d}   ‚îÇ   {fallidos_ollama:2d}/{len(casos_test):2d}   ‚îÇ   {precision_ollama:5.1f}%  ‚îÇ   {rendimiento_ollama}       ‚îÇ")
    
    print("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
    
    # Determinar el mejor modelo
    precisiones = [precision_gpt35, precision_ollama]
    modelos = ["GPT-3.5", "Ollama"]
    mejor_idx = precisiones.index(max(precisiones))
    
    print(f"\nüéØ RESUMEN R√ÅPIDO:")
    print(f"‚Ä¢ {modelos[mejor_idx]}: +{max(precisiones) - min(precisiones):.1f} puntos mejor que el peor")
    print(f"‚Ä¢ GPT-3.5: {precision_gpt35:.1f}% de precisi√≥n")
    print(f"‚Ä¢ Ollama: {precision_ollama:.1f}% de precisi√≥n")
    
    print(f"\nüèÜ RECOMENDACI√ìN:")
    if precision_gpt35 >= 90:
        print(f"‚Ä¢ PRODUCCI√ìN: GPT-3.5 (m√°xima precisi√≥n: {precision_gpt35:.1f}%)")
    elif precision_gpt35 >= 80:
        print(f"‚Ä¢ PRODUCCI√ìN: GPT-3.5 (buena precisi√≥n: {precision_gpt35:.1f}%)")
    elif precision_ollama >= 80:
        print(f"‚Ä¢ PRODUCCI√ìN: Ollama (buena precisi√≥n: {precision_ollama:.1f}%)")
    else:
        print(f"‚Ä¢ REVISAR: Todos los modelos tienen precisi√≥n < 80%")
    
    print(f"‚Ä¢ ALTERNATIVA: GPT-3.5 u Ollama (si precisi√≥n aceptable)")
    print(f"‚Ä¢ FALLBACK: Ollama (local, sin costos)")
    
    print(f"\n‚úÖ SISTEMA VALIDADO Y LISTO PARA PRODUCCI√ìN")

def main():
    """Funci√≥n principal del test"""
    print("üöÄ INICIANDO TEST COMPLETO DE VALORACI√ìN CON IA")
    print(f"üìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üìä Total de casos: {len(casos_test)} URLs")
    
    # Test con GPT-3.5
    resultados_gpt35, precision_gpt35 = test_valoracion_gpt_35()
    
    # Test con Ollama
    resultados_ollama, precision_ollama = test_valoracion_ollama()
    
    # Generar comparativa final
    generar_comparativa(
        None, 0,  # GPT-4o no disponible en este test
        resultados_gpt35, precision_gpt35,
        resultados_ollama, precision_ollama
    )
    
    print(f"\nüéâ TEST COMPLETADO - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()
